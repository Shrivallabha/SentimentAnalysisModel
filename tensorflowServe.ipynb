{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflowServe.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhxHkTyyMUlw",
        "outputId": "3a8b2b14-9a7b-4a84-c6b1-d1fc4e24e7f5"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0  25370      0 --:--:-- --:--:-- --:--:-- 25370\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:11 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [444 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,692 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,372 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [54.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [265 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,134 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [236 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,824 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,243 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [866 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.5 kB]\n",
            "Fetched 11.5 MB in 3s (3,961 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "68 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AHn_-5AMoJc",
        "outputId": "71bf4b5e-2bc5-4ea2-db9c-23f53a09ff5b"
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 68 not upgraded.\n",
            "Need to get 210 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.3.0 [210 MB]\n",
            "Fetched 210 MB in 3s (79.4 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.3.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.3.0) ...\n",
            "Setting up tensorflow-model-server (2.3.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5TNWbJhM81N"
      },
      "source": [
        "### Start running TensorFlow Serving\n",
        "This is where we start running TensorFlow Serving and load our model. After it loads we can start making inference requests using REST. There are some important parameters:\n",
        "\n",
        "* rest_api_port: The port that you'll use for REST requests.\n",
        "* model_name: You'll use this in the URL of REST requests. It can be anything.\n",
        "* model_base_path: This is the path to the directory where you've saved your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU8cXvLzOT7A",
        "outputId": "2e106d4d-5684-4f18-a5c5-90c716e39ead"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lauh2JGqUXLN",
        "outputId": "80138b1b-3b71-4993-81e3-e16f93ff086f"
      },
      "source": [
        "%cd MyDrive/TFX/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/TFX\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyHG9f-vVLl0",
        "outputId": "1f432deb-2e5a-4ad5-faf2-abfa41dd96af"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exported_model_latest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeeUcswGOUkJ",
        "outputId": "544daf5f-6a8e-4e42-bce9-9f387102f9f5"
      },
      "source": [
        "%cd MyDrive/BDS7245/case_study_4/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/BDS7245/case_study_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVT-8HBXQoVw",
        "outputId": "314e8d42-1abb-4cc3-86cd-81b5c3f771b9"
      },
      "source": [
        "ls exported_model_latest/9/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZVmrTqnUxX4"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3c_JjpHSoXo",
        "outputId": "91e29c57-f056-42d9-e185-1656b1da70d9"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "print(\"Installing dependencies for Colab environment\")\n",
        "!pip install -Uq grpcio==1.26.0\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print('TensorFlow version: {}'.format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies for Colab environment\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 5.9MB/s \n",
            "\u001b[?25hTensorFlow version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NoN8isaQpye"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR = \"/gdrive/My Drive/TFX/exported_model_latest\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrYTZi39SgW6",
        "outputId": "ba6986bd-9a5d-4fbd-f4a6-79659466d753"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=exported_model_latest \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 2 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9zdNhB9S4wd",
        "outputId": "72b516b7-1716-4cd7-b2f9-3189b80905d3"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-04 06:03:10.737817: I tensorflow_serving/model_servers/server_core.cc:575]  (Re-)adding model: exported_model_latest\n",
            "2020-12-04 06:03:10.847907: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: exported_model_latest version: 9}\n",
            "2020-12-04 06:03:10.848052: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: exported_model_latest version: 9}\n",
            "2020-12-04 06:03:10.848126: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: exported_model_latest version: 9}\n",
            "2020-12-04 06:03:10.848979: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /gdrive/My Drive/TFX/exported_model_latest/9\n",
            "2020-12-04 06:03:11.526226: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
            "2020-12-04 06:03:11.526535: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:234] Reading SavedModel debug info (if present) from: /gdrive/My Drive/TFX/exported_model_latest/9\n",
            "2020-12-04 06:03:11.527342: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-12-04 06:03:11.932671: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:199] Restoring SavedModel bundle.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lochfw97S8C5",
        "outputId": "58e4bc53-de25-4b29-c5e6-1015a8edea2a"
      },
      "source": [
        "import tempfile\n",
        "\n",
        "tempfile.gettempdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6vpS0YSTe02",
        "outputId": "efca8127-c4c4-4f16-a3dd-1e2c2c8b32fe"
      },
      "source": [
        "%%bash  \n",
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exported_model_latest\n",
            "server.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9ZHEr97ZGGK",
        "outputId": "bad0716f-15ac-4fea-c3a0-da70f81900ed"
      },
      "source": [
        "%%bash\n",
        "realpath exported_model_latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/.shortcut-targets-by-id/100l7BvgP9GvwqwAZtVIj5K-s-Zt7sdkK/exported_model_latest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfU2pxvucp1d",
        "outputId": "ba65a46b-86df-47bb-c166-f7a89ce89c31"
      },
      "source": [
        "import json\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [\"it was good\"]})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: {\"signature_name\": \"serving_default\", \"instances\": ... e\": \"serving_default\", \"instances\": [\"it was good\"]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM9Gcm_yewvd"
      },
      "source": [
        "!pip install -q requests\n",
        "\n",
        "import requests\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/exported_model_latest:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWdhu_CTfbUO",
        "outputId": "98564d58-a288-4b6d-c13a-4ce948465c16"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'error': \"Could not parse example input, value: 'it was good'\\n\\t [[{{node ParseExample/ParseExampleV2}}]]\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYwc-z4ZfgVb"
      },
      "source": [
        "import requests\n",
        "import tensorflow as tf\n",
        "import base64\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def serialize_text(text):\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'text': _bytes_feature(text)\n",
        "        }))\n",
        "    serialized_example = example.SerializeToString()\n",
        "    return serialized_example\n",
        "\n",
        "model_server_url = 'http://localhost:8501/v1/models/exported_model_latest:predict'\n",
        "\n",
        "def predict(text):\n",
        "    example = serialize_text(text)\n",
        "    json_data = {\n",
        "      \"signature_name\":\"serving_default\",\n",
        "      \"instances\":[\n",
        "        {\n",
        "          \"examples\":{\"b64\": base64.b64encode(example).decode('utf-8')}\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "    resp = requests.post(model_server_url, json=json_data)\n",
        "    return resp.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UkJb4AgrDwr",
        "outputId": "9afab897-53ea-497f-9c41-2a111b952949"
      },
      "source": [
        "text = b\"This is the worst show ever produced for TV. Each episode is a flop. The casting, the writing, the timing are all really bad.\"\n",
        "print(predict(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'predictions': [[0.033854723]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHWQsPDcci8Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}